---
title: "Macroinvertebrate Data Analysis"
author: "Marney Pratt"
date: "October 12, 2022"
format: pdf
---

## Getting Setup

Before getting started, it is a good practice to start with a clean slate by restarting your R session

Go to the top menu, select Session then select Restart R

Keep all of your analysis in this same .qmd file and keep all the associated files in the project folder. Make sure the project name is showing in the upper right of the RStudio window.


# Load packages

```{r setup}
#| message: false

library(tidyverse) ## for readr, dplyr, ggplot2
library(vegan) ## for calculating diversity measures (you can remove this if you are not calculating diversity measures)
library(ggbeeswarm) ## for jittering points
library(flextable) ## for making formatted tables

```

# Import Data

Figure out which data file(s) you need to import. Find the code you need in the "importing_data" folder within the "script_templates" folder. Copy and paste the code you need in the chunk below.

```{r import data}

env <- read_csv("data/env.csv",
                 col_types = cols(date = col_date(format = "%Y-%m-%d"),
                  
                  location = col_factor(levels = c(
                    "Downstream","Upstream")), 
                  
                  season = col_factor(levels = c("Summer","Fall")), 
                  
                  year = col_factor()
                 )) 

macros <- read_csv("data/macros.csv",
                 col_types = cols(date = col_date(format = "%Y-%m-%d"),
                  
                  location = col_factor(levels = c(
                    "Downstream","Upstream")), 
                  
                  season = col_factor(levels = c("Summer","Fall")), 
                  
                  year = col_factor()
                 )) 


master.taxa <- read_csv("data/master.taxa.csv") %>% 
  distinct()


waterQ <- read_csv("data/waterQ.csv",
                 col_types = cols(date = col_date(format = "%Y-%m-%d"),
                  
                  location = col_factor(levels = c(
                    "Downstream","Upstream")), 
                  
                  season = col_factor(levels = c("Summer","Fall")), 
                  
                  year = col_factor()
                 )) 


```

# Data Wrangling

Find the code you need to prepare or "wrangle" your data to make any calculations needed and combine any datasets you need to combine by looking in the "data_wrangling" folder within the "script_templates" folder. Copy and paste the code you need in the chunk below.

```{r data wrangling}

#calculate limpet density for each sampleID
limpet.density <- macros %>% 
  
  #join taxa info
  left_join(., master.taxa) %>%
  
  # Summarize for each sampleID and each family 
  # change group_by function to remove or add grouping variables as needed 
  # if you want a specific group of organisms, add that column name into 
  # the list of grouping variables (family, organism_aggr, FFG, etc)
  # then filter for the organism or group you want
  group_by(sampleID, family) %>% 
  dplyr::summarise (density = sum(invDens, na.rm = TRUE)) %>% 

  #fill in group combos where there were none present with zeros
  ungroup() %>% 
  complete(sampleID, family,
           fill = list(density = 0)) %>% 
  
  #filter for limpets
  filter(family == "Ancylidae")

#get sample info
sample.info <- macros %>%
  select(date, sampleID, season, year, location, benthicArea) %>% 
  distinct()

#add sample info back to density data
limpet.density <- left_join(limpet.density, sample.info)


#select desired variables from env
env2 <- env %>% 
  select(date, sampleID, season, year, location, 
         depth, per_rock, pH, DO, wTemp, light, flow,
         mon.precip, mon.ADD) 

#add env variables to density data
limpet.df <- left_join(limpet.density, env2) 


```

# Data Description


Make a formatted table of the data that you used in your analysis to include in the Data Analysis Methods section of your paper.

```{r table of data used}

table.sum <- limpet.df %>% 
  
  #summarize by date, year, season, location (to get number of microhabs sampled per date)
  group_by(date, season, location) %>% 
    summarize(
      area = sum(benthicArea),
      mon.ADD = mean(mon.ADD, na.rm=TRUE),
      mon.precip = mean(mon.precip, na.rm=TRUE),
      samples = n()
    ) %>% 
  
  #change date to year-month-day
  mutate(date = format(as.Date(date), '%Y-%m-%d')) %>% 


  #summarize by season, location 
  group_by(season, location) %>% 
    summarize(
      dates = str_c(date, collapse = ", "),
      samples = sum(samples),
      area = sum(area)
    )  
  

#create the formatted
ft <- flextable(table.sum)

#create header labels
ft <- set_header_labels(ft,
                        year = "Year",
                        season = "Season",
                        location = "Location",
                        dates = "Sampling Dates",
                        samples = "# of Samples",
                        area = "Total Area Sampled (m^2)"
                        )


#bold the headings
ft <- bold(ft, part="header")

ft <- merge_v(ft, j = ~ season)

#set table properties
ft <- set_table_properties(ft, layout = "autofit", width = 1)

#center columns
ft <- align(ft, align = "center", part = "all" )


#add lines between year x season
ft <- theme_vanilla(ft) %>% 
  fontsize(size = 10)

ft <- fix_border_issues(ft)

#print table
#ft

#send to MS Word if desired
#comment out or delete the line below before you knit an R Markdown document
#print(ft, preview = "docx") # can change this to "html" or "pptx"

#see https://davidgohel.github.io/flextable/ for more information and formatting options

```

Use the template code below to calculate the descriptive statistics for your variable of interest. The output of this code should not all be reported in your paper. Decide which (if any) of the descriptive statistics you should report and make sure to round the values. Descriptive statistics can be reported in the text of the results (see this example results section) if relatively simple, or you can make a formatted table of just the necessary, rounded values to include in your paper (in which case you might want to use "formatted_descriptiveStats_table.R" in the "data_description" script templates to help you make a formatted table).

```{r descriptive stats}

# the code below will calculate descriptive statistics for a variable of interest grouped by another variable

density.sum <- limpet.df %>% # put the name of the data frame here
  filter(!is.na(density)) %>% # remove missing values from the variable of interest
  group_by(season, location) %>% # put the name of the grouping variable(s) here
  summarize(mean = mean(density), # put the name of the variable you want to summarize in this & following blanks
            median = median(density), 
            SD = sd(density), 
            IQR = IQR(density), 
            min = min(density),
            max = max(density),
            N = n())

density.sum


DO.sum <- limpet.df %>% # put the name of the data frame here
  filter(!is.na(DO)) %>% # remove missing values from the variable of interest
  group_by(season, location) %>% # put the name of the grouping variable(s) here
  summarize(mean = mean(DO), # put the name of the variable you want to summarize in this & following blanks
            median = median(DO), 
            SD = sd(DO), 
            IQR = IQR(DO), 
            min = min(DO),
            max = max(DO),
            N = n())
DO.sum

```



# Data Visualization

Find the code you need to visualize (=graph) your data by looking in the "graphing" folder within the "script_templates" folder. Copy and paste the code you need in the chunk below.



```{r}

limpet.df %>% 
 # filter(season == "Fall") %>% 

ggplot(
  data = .,   #put the data frame name here
  aes(x = location, y = log(density+1),                 #1st factor = x, continuous variable = y,
      fill = location, color = location)) +       #2nd factor = fill & color
  geom_quasirandom( 
    shape=21, size=2, alpha = 0.5, width=0.2, #play with these values as needed
    dodge.width = 1,  show.legend = FALSE) + #adjust the dodge width as needed
  stat_summary(fun = median, 
               fun.min = median, 
               fun.max = median, #change median to mean if desired
               geom = "crossbar", na.rm = TRUE,
               width = 0.5, size = 0.5, #play with these values as needed
               color = "black",
               position=position_dodge(width=1), #match this width to dodge.width above
               show.legend = FALSE) + 
  ylab(bquote("Log Density +1 (number/"~m^2*")")) +
  xlab("Location") +
  coord_cartesian(expand=TRUE) +
  theme_classic(base_size=16) +
  facet_wrap(vars(season))   #3rd factor here


```
```{r Save your graph1, eval = F}

# save the graph!
ggsave(filename="location.png",  #recommended to use.png or .jpg file types
       height = 7, width = 8, units = "in", 
       dpi = 300)

```


```{r}

limpet.df %>% 
ggplot(
  data = ., 
  aes(x = DO, y = density+1, color = location)) + 
  geom_point(size = 3) +                   #play with the point attributes as needed
  geom_smooth(method = "lm", se = FALSE) + #adds line of best fit
  ylab(bquote("Log Density + 1 (number/"~m^2*")")) +
  xlab("Dissolved Oxygen (mg/L)") +
  labs(color = "Location") +
  theme_classic(base_size = 16) +
  scale_y_log10() +     #changes y-axis to log-scale
  annotation_logticks(sides = "l") + # adds log-scale tick marks to the left axis 
  facet_wrap(vars(season)) 

  
```




To save your graph with the `ggsave()` function, you need to name the resulting file with surrounding " ", and indicate the size via height, width, and units. Don't forget to save the graph with a dpi call between 300-500 to make it nice and crisp! Look at the `ggsave()` help file for more information and options.

```{r Save your graph, eval = F}

# save the graph!
ggsave(filename="DO.png",  #recommended to use.png or .jpg file types
       height = 7, width = 8, units = "in", 
       dpi = 300)

```


# Citing R in Your Paper

In the Data Analysis Methods section of your paper, you need to cite how the data were analyzed including (1) any calculations done (for example, how was density calculated?), and (2) what software was used for the analysis.

Here is a detailed explanation of How to Cite R in your Methods.

You need to cite base R but how will you know what version of R you are using?

You should also cite the most important packages used.

All of you should cite the {tidyverse} super package since we used {reader} and {dplyr} to import and wrangle our data. If you used the dot plot in your paper, then you used {ggplot2} which is part of the {tidyverse} (so you don't need to cite it separately), but also {ggbeeswarm} which is NOT part of the {tidyverse} so it needs to be cited separately. If you used the formatted table in your paper, then cite the {flextable} package.

To properly cite all the packages listed above, you need to find out the information needed for each package. Run the code below to determine the version of R and packages used.

```{r sessionInfo}

sessionInfo()

```

The above is the information you need to cite which version of R as well as any packages you used. While the version number is necessary, you also need more information to cite R and the packages. Refer to [How to Cite R in your Methods](https://docs.google.com/presentation/d/1RG4_R-MDOy1vbMz-M1gfOcMtgqWu9Kvv_R4ex5QdcVk/edit?usp=sharing) to help you figure out how to cite in the text as well as the full citation in the Literature Cited section at the end of your paper.

Use the code below to get more necessary information to cite R itself  

```{r cite R}

#citation info for base R 
citation()

```


Use the code below to cite the {tidyverse} package and then repeat the code replacing `tidyverse` with any other packages you need to cite

```{r cite tidyverse}

#citation info for base R 
citation("tidyverse")

```

## Rendering

Don't forget to "render" your .qmd file when you are done. Make sure that each code chunk has an unique name or no name before you render. Make sure all your files are in the project folder.

Render straight to PDF or render to HTML, open the HTML file in your browser, and then "print" to a PDF file.

Insert a file printout of the PDF in the "Project Data Analysis" section of your Lab Notebook.
